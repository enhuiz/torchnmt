dataset:
  proto: XiaoshiDataset
  root: data/xiaoshi
  src: tra
  tgt: org
  vocab_share: true

model:
  proto: Transformer
  vocab_share: true

  encoder:
    proto: TransformerEncoder
    model_dim: 512
    ffn_dim: 2048
    layers: 6
    heads: 8
    vocab_size: 4104

  decoder:
    proto: TransformerDecoder
    model_dim: 512
    ffn_dim: 2048
    layers: 6
    heads: 8
    vocab_size: 4104

train:
  proto: NMTTrainer
  device: cuda
  lr: 0.001
  batch_size: 8
  epochs: 50
  continued: true
  save_every: 5

test:
  proto: NMTTester
  device: cuda
  batch_size: 32
  beam_width: 5
  splits: [val]
  max_len: 20
  all: true
