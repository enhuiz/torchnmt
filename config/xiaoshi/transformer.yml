dataset:
  proto: XiaoshiDataset
  root: data/xiaoshi
  src: tra
  tgt: org
  vocab_share: true

model:
  proto: Transformer
  vocab_share: true

  encoder:
    proto: TransformerEncoder
    model_dim: 512
    ffn_dim: 2048
    layers: 6
    heads: 8
    vocab_size: 4221

  decoder:
    proto: TransformerDecoder
    model_dim: 512
    ffn_dim: 2048
    layers: 6
    heads: 8
    vocab_size: 4221

train:
  proto: NMTTrainer
  device: cuda
  lr: 0.01
  batch_size: 8
  epochs: 30
  continued: true
  save_every: 10

test:
  proto: NMTTester
  device: cuda
  batch_size: 32
  beam_width: 20
  splits: [val]
  max_len: 50
  all: false
