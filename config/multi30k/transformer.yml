dataset:
  proto: Multi30kDataset
  root: data/multi30k
  src: de.atok
  tgt: en.atok

model:
  proto: Transformer

  encoder:
    proto: TransformerEncoder
    model_dim: 512
    ffn_dim: 2048
    layers: 6
    heads: 8
    vocab_size: 17831 # de

  decoder:
    proto: TransformerDecoder
    model_dim: 512
    ffn_dim: 2048
    layers: 6
    heads: 8
    vocab_size: 9690 # en

train:
  proto: NMTTrainer
  device: cuda
  lr: 0.001
  batch_size: 8
  epochs: 30
  continued: true
  save_every: 10
  splits:
    train: "train"
    val: "val"

test:
  proto: NMTTester
  device: cuda
  batch_size: 32
  beam_width: 1
  splits: [val, test]
  max_len: 52
  all: false
